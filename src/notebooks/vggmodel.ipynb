{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "351ab95e",
   "metadata": {},
   "source": [
    "# Running the small pizza_steak_sushi dataset on VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c1cc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "device  = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f078d6",
   "metadata": {},
   "source": [
    "# Importing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89cdd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG16(\n",
       "  (conv_block_1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_block_3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=200704, out_features=512, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.modelclass.models import VGG16\n",
    "\n",
    "model_0 = VGG16(num_classes = 3)\n",
    "model_0.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cf9903",
   "metadata": {},
   "source": [
    "# creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13d8a574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pizza_steak_sushi\\train\n",
      "pizza_steak_sushi\\test\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"./pizza_steak_sushi\")\n",
    "train_dir = data_dir / \"train\"\n",
    "test_dir = data_dir / \"test\"\n",
    "\n",
    "print(train_dir)\n",
    "print(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c9524eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train transform: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=None, hue=None)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "Test transform: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    # transforms.TrivialAugmentWide(),  # Still lightweight\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(size = (224 , 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(                     # Normalize to ImageNet mean/std\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "print(f\"Train transform: {train_transform}\")\n",
    "print(f\"Test transform: {test_transform}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18dd3ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 677\n",
      "    Root location: pizza_steak_sushi\\train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               RandomRotation(degrees=[-10.0, 10.0], interpolation=nearest, expand=False, fill=0)\n",
      "               ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=None, hue=None)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 192\n",
      "    Root location: pizza_steak_sushi\\test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "['pizza', 'steak', 'sushi']\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "train_dataset = ImageFolder(\n",
    "    root = train_dir,\n",
    "    transform = train_transform   \n",
    ")\n",
    "\n",
    "test_dataset = ImageFolder(\n",
    "    root = test_dir,\n",
    "    transform = test_transform\n",
    ")\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "classes = train_dataset.classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4156ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset = train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 0,\n",
    "    shuffle = True,\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset = test_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    num_workers = 0,\n",
    "    shuffle = False,\n",
    "    pin_memory = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697a625d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "image, label = next(iter(train_dataloader))\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "185be9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VGG16                                    [32, 3]                   --\n",
       "├─Sequential: 1-1                        [32, 64, 112, 112]        --\n",
       "│    └─Conv2d: 2-1                       [32, 64, 224, 224]        1,792\n",
       "│    └─BatchNorm2d: 2-2                  [32, 64, 224, 224]        128\n",
       "│    └─ReLU: 2-3                         [32, 64, 224, 224]        --\n",
       "│    └─Conv2d: 2-4                       [32, 64, 224, 224]        36,928\n",
       "│    └─BatchNorm2d: 2-5                  [32, 64, 224, 224]        128\n",
       "│    └─ReLU: 2-6                         [32, 64, 224, 224]        --\n",
       "│    └─MaxPool2d: 2-7                    [32, 64, 112, 112]        --\n",
       "├─Sequential: 1-2                        [32, 128, 56, 56]         --\n",
       "│    └─Conv2d: 2-8                       [32, 128, 112, 112]       73,856\n",
       "│    └─BatchNorm2d: 2-9                  [32, 128, 112, 112]       256\n",
       "│    └─ReLU: 2-10                        [32, 128, 112, 112]       --\n",
       "│    └─Conv2d: 2-11                      [32, 128, 112, 112]       147,584\n",
       "│    └─BatchNorm2d: 2-12                 [32, 128, 112, 112]       256\n",
       "│    └─ReLU: 2-13                        [32, 128, 112, 112]       --\n",
       "│    └─MaxPool2d: 2-14                   [32, 128, 56, 56]         --\n",
       "├─Sequential: 1-3                        [32, 256, 28, 28]         --\n",
       "│    └─Conv2d: 2-15                      [32, 256, 56, 56]         295,168\n",
       "│    └─BatchNorm2d: 2-16                 [32, 256, 56, 56]         512\n",
       "│    └─ReLU: 2-17                        [32, 256, 56, 56]         --\n",
       "│    └─Conv2d: 2-18                      [32, 256, 56, 56]         590,080\n",
       "│    └─BatchNorm2d: 2-19                 [32, 256, 56, 56]         512\n",
       "│    └─ReLU: 2-20                        [32, 256, 56, 56]         --\n",
       "│    └─MaxPool2d: 2-21                   [32, 256, 28, 28]         --\n",
       "├─Sequential: 1-4                        [32, 3]                   --\n",
       "│    └─Flatten: 2-22                     [32, 200704]              --\n",
       "│    └─Linear: 2-23                      [32, 512]                 102,760,960\n",
       "│    └─ReLU: 2-24                        [32, 512]                 --\n",
       "│    └─Dropout: 2-25                     [32, 512]                 --\n",
       "│    └─Linear: 2-26                      [32, 3]                   1,539\n",
       "==========================================================================================\n",
       "Total params: 103,909,699\n",
       "Trainable params: 103,909,699\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 243.18\n",
       "==========================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 5754.72\n",
       "Params size (MB): 415.64\n",
       "Estimated Total Size (MB): 6189.62\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model_0 , input_size=(32,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbe7def0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "\n",
    "optimizer = Adam(model_0.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c5bb1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bc4f3ace1d483696ee99839c21dddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] Allocated: 1616.52 MB | Reserved: 6490.00 MB\n",
      "Epoch:0\tTrain Loss:13.0905\tTrain Acc:0.4605\tTest Loss:11.6124\tTest Acc:0.4844\n",
      "[] Allocated: 1616.52 MB | Reserved: 6490.00 MB\n",
      "Epoch:1\tTrain Loss:9.5754\tTrain Acc:0.4614\tTest Loss:10.1438\tTest Acc:0.5312\n",
      "[] Allocated: 1616.52 MB | Reserved: 6490.00 MB\n",
      "Epoch:2\tTrain Loss:8.5611\tTrain Acc:0.5040\tTest Loss:10.0608\tTest Acc:0.5052\n"
     ]
    }
   ],
   "source": [
    "from helper.Process import run_train_test\n",
    "\n",
    "results = run_train_test(\n",
    "    model = model_0,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    device= device,\n",
    "    epochs=3\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
